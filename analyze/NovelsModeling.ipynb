{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Writer Name</th>\n",
       "      <th>Novel Name</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Final Word Count</th>\n",
       "      <th>Daily Average</th>\n",
       "      <th>Winner</th>\n",
       "      <th>Synopses</th>\n",
       "      <th>url</th>\n",
       "      <th>Novel Date</th>\n",
       "      <th>Excerpt</th>\n",
       "      <th>...</th>\n",
       "      <th>num uniques</th>\n",
       "      <th>num sentences</th>\n",
       "      <th>paragraphs</th>\n",
       "      <th>fk score</th>\n",
       "      <th>has excerpt</th>\n",
       "      <th>num words excerpt</th>\n",
       "      <th>num uniques excerpt</th>\n",
       "      <th>num sentences excerpt</th>\n",
       "      <th>paragraphs excerpt</th>\n",
       "      <th>fk score excerpt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nicaless</td>\n",
       "      <td>Novel: Lauren's Birthday</td>\n",
       "      <td>Young Adult</td>\n",
       "      <td>24229</td>\n",
       "      <td>807</td>\n",
       "      <td>0</td>\n",
       "      <td>\\n&lt;p&gt;&lt;/p&gt;\\n</td>\n",
       "      <td>http://nanowrimo.org/participants/nicaless/nov...</td>\n",
       "      <td>November 2015</td>\n",
       "      <td>\\n&lt;p&gt;&lt;/p&gt;\\n</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nicaless</td>\n",
       "      <td>Novel: A Mystery in the Kingdom of Aermon</td>\n",
       "      <td>Fantasy</td>\n",
       "      <td>50919</td>\n",
       "      <td>1,697</td>\n",
       "      <td>1</td>\n",
       "      <td>\\n&lt;p&gt;Hitoshi is appointed the youngest Judge a...</td>\n",
       "      <td>http://nanowrimo.org/participants/nicaless/nov...</td>\n",
       "      <td>November 2014</td>\n",
       "      <td>\\n&lt;p&gt;This story, funnily enough, started out a...</td>\n",
       "      <td>...</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>65.73</td>\n",
       "      <td>1</td>\n",
       "      <td>132</td>\n",
       "      <td>96</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>78.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rachel B. Moore</td>\n",
       "      <td>Novel: Finding Fortunato</td>\n",
       "      <td>Literary</td>\n",
       "      <td>50603</td>\n",
       "      <td>1,686</td>\n",
       "      <td>1</td>\n",
       "      <td>\\n&lt;p&gt;Sam and Anna Gold and their newly adoptiv...</td>\n",
       "      <td>http://nanowrimo.org/participants/rachel-b-moo...</td>\n",
       "      <td>November 2015</td>\n",
       "      <td>\\n&lt;p&gt;&lt;/p&gt;\\n</td>\n",
       "      <td>...</td>\n",
       "      <td>109</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>58.62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rachel B. Moore</td>\n",
       "      <td>Novel: The Residency</td>\n",
       "      <td>Literary</td>\n",
       "      <td>50425</td>\n",
       "      <td>1,680</td>\n",
       "      <td>1</td>\n",
       "      <td>\\n&lt;p&gt;It's every writer's dream - an all-expens...</td>\n",
       "      <td>http://nanowrimo.org/participants/rachel-b-moo...</td>\n",
       "      <td>November 2014</td>\n",
       "      <td>\\n&lt;p&gt;&lt;/p&gt;\\n</td>\n",
       "      <td>...</td>\n",
       "      <td>51</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>65.73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rachel B. Moore</td>\n",
       "      <td>Novel: The Jew From Fortunato</td>\n",
       "      <td>Literary Fiction</td>\n",
       "      <td>41447</td>\n",
       "      <td>1,381</td>\n",
       "      <td>0</td>\n",
       "      <td>\\n&lt;p&gt;20-something Andre Levinsky is a fish out...</td>\n",
       "      <td>http://nanowrimo.org/participants/rachel-b-moo...</td>\n",
       "      <td>November 2013</td>\n",
       "      <td>\\n&lt;p&gt;&lt;/p&gt;\\n</td>\n",
       "      <td>...</td>\n",
       "      <td>93</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>56.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Writer Name                                 Novel Name  \\\n",
       "0         Nicaless                   Novel: Lauren's Birthday   \n",
       "1         Nicaless  Novel: A Mystery in the Kingdom of Aermon   \n",
       "2  Rachel B. Moore                   Novel: Finding Fortunato   \n",
       "3  Rachel B. Moore                       Novel: The Residency   \n",
       "4  Rachel B. Moore              Novel: The Jew From Fortunato   \n",
       "\n",
       "              Genre  Final Word Count Daily Average  Winner  \\\n",
       "0       Young Adult             24229           807       0   \n",
       "1           Fantasy             50919         1,697       1   \n",
       "2          Literary             50603         1,686       1   \n",
       "3          Literary             50425         1,680       1   \n",
       "4  Literary Fiction             41447         1,381       0   \n",
       "\n",
       "                                            Synopses  \\\n",
       "0                                        \\n<p></p>\\n   \n",
       "1  \\n<p>Hitoshi is appointed the youngest Judge a...   \n",
       "2  \\n<p>Sam and Anna Gold and their newly adoptiv...   \n",
       "3  \\n<p>It's every writer's dream - an all-expens...   \n",
       "4  \\n<p>20-something Andre Levinsky is a fish out...   \n",
       "\n",
       "                                                 url     Novel Date  \\\n",
       "0  http://nanowrimo.org/participants/nicaless/nov...  November 2015   \n",
       "1  http://nanowrimo.org/participants/nicaless/nov...  November 2014   \n",
       "2  http://nanowrimo.org/participants/rachel-b-moo...  November 2015   \n",
       "3  http://nanowrimo.org/participants/rachel-b-moo...  November 2014   \n",
       "4  http://nanowrimo.org/participants/rachel-b-moo...  November 2013   \n",
       "\n",
       "                                             Excerpt        ...         \\\n",
       "0                                        \\n<p></p>\\n        ...          \n",
       "1  \\n<p>This story, funnily enough, started out a...        ...          \n",
       "2                                        \\n<p></p>\\n        ...          \n",
       "3                                        \\n<p></p>\\n        ...          \n",
       "4                                        \\n<p></p>\\n        ...          \n",
       "\n",
       "   num uniques  num sentences  paragraphs  fk score  has excerpt  \\\n",
       "0            0              0           0      0.00            0   \n",
       "1           42              3           1     65.73            1   \n",
       "2          109              7           4     58.62            0   \n",
       "3           51              4           3     65.73            0   \n",
       "4           93              4           1     56.93            0   \n",
       "\n",
       "   num words excerpt  num uniques excerpt  num sentences excerpt  \\\n",
       "0                  0                    0                      0   \n",
       "1                132                   96                     13   \n",
       "2                  0                    0                      0   \n",
       "3                  0                    0                      0   \n",
       "4                  0                    0                      0   \n",
       "\n",
       "   paragraphs excerpt  fk score excerpt  \n",
       "0                   0              0.00  \n",
       "1                   7             78.25  \n",
       "2                   0              0.00  \n",
       "3                   0              0.00  \n",
       "4                   0              0.00  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "novel_features = pd.read_csv(\"../clean data/novel_features.csv\", index_col = 0)\n",
    "novel_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'Winner', u'Novel Date', u'has genre', u'standard genre',\n",
       "       u'has_synopses', u'num words', u'num uniques', u'num sentences',\n",
       "       u'paragraphs', u'fk score', u'has excerpt', u'num words excerpt',\n",
       "       u'num uniques excerpt', u'num sentences excerpt', u'paragraphs excerpt',\n",
       "       u'fk score excerpt'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del novel_features['Novel Name']\n",
    "del novel_features['Genre']\n",
    "del novel_features['Final Word Count']\n",
    "del novel_features['Daily Average']\n",
    "del novel_features['Synopses']\n",
    "del novel_features['url']\n",
    "del novel_features['Excerpt']\n",
    "del novel_features['Writer Name']\n",
    "novel_features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.437125748503 is the fraction of winners in the test data\n",
      "0.686806411837 is the fraction of winners in the train data\n"
     ]
    }
   ],
   "source": [
    "nov2015 = novel_features[novel_features['Novel Date'] == \"November 2015\"]\n",
    "not_nov2015 = novel_features[novel_features['Novel Date'] != \"November 2015\"]\n",
    "print str(sum(nov2015['Winner'] / float(len(nov2015)))) + \" is the fraction of winners in the test data\"\n",
    "print str(sum(not_nov2015['Winner'] / float(len(not_nov2015)))) + \" is the fraction of winners in the train data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = novel_features['Winner'].values\n",
    "del novel_features['Winner']\n",
    "\n",
    "currentnovels = novel_features['Novel Date'] == \"November 2015\"\n",
    "currentnovels.values\n",
    "\n",
    "pastnovels = novel_features['Novel Date'] != \"November 2015\"\n",
    "pastnovels.values\n",
    "\n",
    "del novel_features['Novel Date']\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cross_validation import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.26264592,  0.6768341 , -1.34469367, ..., -0.25943684,\n",
       "        -0.12867299, -0.32128503],\n",
       "       [ 0.26264592,  0.6768341 ,  0.7436638 , ...,  0.07515182,\n",
       "         0.41195729,  1.23610056],\n",
       "       [ 0.26264592,  0.6768341 ,  0.7436638 , ..., -0.25943684,\n",
       "        -0.12867299, -0.32128503],\n",
       "       ..., \n",
       "       [ 0.26264592,  0.6768341 ,  0.7436638 , ..., -0.25943684,\n",
       "        -0.12867299, -0.32128503],\n",
       "       [ 0.26264592,  0.6768341 ,  0.7436638 , ..., -0.25943684,\n",
       "        -0.12867299, -0.32128503],\n",
       "       [ 0.26264592,  0.6768341 , -1.34469367, ..., -0.25943684,\n",
       "        -0.12867299, -0.32128503]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "features_norm = scaler.fit_transform(novel_features)\n",
    "features_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testX = features_norm[currentnovels.values]\n",
    "testy = y[currentnovels.values]\n",
    "\n",
    "trainX = features_norm[pastnovels.values]\n",
    "trainy = y[pastnovels.values]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we saw above, the ratio of winners to non-winners in the train data is almost 70/30.  That's quite imbalanced.  Let's rebalance the train data close to 50/50 first.  We'll do this by oversampling the underrepresented class - the non-winners.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Determining classes statistics... 2 classes detected: {0: 508, 1: 1114}\n",
      "Over-sampling performed: Counter({1: 1114, 0: 1016})\n"
     ]
    }
   ],
   "source": [
    "from unbalanced_dataset import OverSampler, SMOTE\n",
    "\n",
    "OS = OverSampler()\n",
    "trainX,trainy = OS.fit_transform(trainX,trainy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.52354078033119655"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lr = LogisticRegression(C=1)\n",
    "cross_val_score(model_lr,trainX,trainy,cv=10).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49500998003992014"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lr = LogisticRegression(C=5).fit(trainX,trainy)\n",
    "model_lr.score(testX, testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.63      0.24      0.35       282\n",
      "          1       0.46      0.82      0.59       219\n",
      "\n",
      "avg / total       0.56      0.50      0.45       501\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print classification_report(testy,model_lr.predict(testX))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not much better than guessing.  Let's try applying PCA before running the Logistic Regression again.\n",
    "\n",
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2.06083002e+00,   8.25685196e-01,   7.86582157e-01, ...,\n",
       "          7.43851687e-03,   6.45786219e-04,  -4.09595202e-03],\n",
       "       [ -1.30623863e+00,   3.21347224e-01,   7.30156876e-01, ...,\n",
       "         -1.10197638e-01,  -6.12617500e-02,  -1.01925944e-01],\n",
       "       [ -1.53347198e+00,  -2.37513049e+00,   4.05354278e-01, ...,\n",
       "         -1.14848059e-01,   1.22494431e-01,  -4.05779459e-02],\n",
       "       ..., \n",
       "       [  6.04951760e-01,  -4.04439337e-01,   7.20642598e-01, ...,\n",
       "          4.33604775e-02,  -5.67164632e-02,   1.15560538e-02],\n",
       "       [ -1.83448544e-01,  -1.11917659e+00,   6.75031346e-01, ...,\n",
       "          9.31620569e-02,  -1.56300438e-01,   6.00946958e-02],\n",
       "       [  2.06083002e+00,   8.25685196e-01,   7.86582157e-01, ...,\n",
       "          7.43851687e-03,   6.45786219e-04,  -4.09595202e-03]])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA()\n",
    "pca_features = pca.fit(features_norm).transform(features_norm)\n",
    "pca_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.36108244,  0.21830197,  0.09792561,  0.0926552 ,  0.07222622,\n",
       "        0.04624275,  0.03658281,  0.03082816,  0.0238363 ,  0.00937815,\n",
       "        0.00485473,  0.00252106,  0.0021151 ,  0.00144952])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Percentage of variance explained\n",
    "\n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try the model again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Determining classes statistics... 2 classes detected: {0: 508, 1: 1114}\n",
      "Over-sampling performed: Counter({1: 1114, 0: 1016})\n"
     ]
    }
   ],
   "source": [
    "pca_testX = pca_features[currentnovels.values]\n",
    "pca_testy = y[currentnovels.values]\n",
    "\n",
    "pca_trainX = pca_features[pastnovels.values]\n",
    "pca_trainy = y[pastnovels.values]\n",
    "\n",
    "OS = OverSampler()\n",
    "pca_trainX, pca_trainy = OS.fit_transform(pca_trainX, pca_trainy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.506643531914\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.58      0.19      0.28       282\n",
      "          1       0.44      0.82      0.57       219\n",
      "\n",
      "avg / total       0.52      0.47      0.41       501\n",
      "\n",
      "0.465069860279\n"
     ]
    }
   ],
   "source": [
    "new_model_lr = LogisticRegression(C=1)\n",
    "\n",
    "print cross_val_score(new_model_lr, pca_trainX, pca_trainy, cv=10).mean()\n",
    "\n",
    "new_model_lr.fit(pca_trainX, pca_trainy)\n",
    "\n",
    "print classification_report(pca_testy,new_model_lr.predict(pca_testX))\n",
    "print new_model_lr.score(pca_testX, pca_testy) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run other models to see if they do any better\n",
    "\n",
    "### K Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.564827393799\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.51      0.34      0.41       282\n",
      "          1       0.41      0.58      0.48       219\n",
      "\n",
      "avg / total       0.46      0.45      0.44       501\n",
      "\n",
      "0.445109780439\n",
      "0.573767636679\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.54      0.33      0.41       282\n",
      "          1       0.42      0.63      0.51       219\n",
      "\n",
      "avg / total       0.49      0.46      0.45       501\n",
      "\n",
      "0.463073852295\n"
     ]
    }
   ],
   "source": [
    "model_knn = KNeighborsClassifier(4)\n",
    "\n",
    "print cross_val_score(model_knn, pca_trainX, pca_trainy, cv=10).mean()\n",
    "\n",
    "model_knn.fit(pca_trainX, pca_trainy)\n",
    "print classification_report(pca_testy,model_knn.predict(pca_testX))\n",
    "print model_knn.score(pca_testX, pca_testy)\n",
    "\n",
    "\n",
    "print cross_val_score(model_knn, trainX, trainy, cv=10).mean()\n",
    "\n",
    "model_knn.fit(trainX, trainy)\n",
    "print classification_report(testy,model_knn.predict(testX))\n",
    "print model_knn.score(testX, testy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surprisingly, K Neighbors is slightly better than Logistic Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "#using Gaussian Naive Bayes because it allows negative inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.492984238234\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.56      0.21      0.31       282\n",
      "          1       0.44      0.79      0.56       219\n",
      "\n",
      "avg / total       0.51      0.46      0.42       501\n",
      "\n",
      "0.463073852295\n",
      "0.497279979767\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.60      0.53      0.56       282\n",
      "          1       0.47      0.54      0.51       219\n",
      "\n",
      "avg / total       0.54      0.53      0.54       501\n",
      "\n",
      "0.534930139721\n"
     ]
    }
   ],
   "source": [
    "model_nb = GaussianNB()\n",
    "print cross_val_score(model_nb, pca_trainX, pca_trainy, cv=10).mean()\n",
    "\n",
    "model_nb.fit(pca_trainX, pca_trainy)\n",
    "print classification_report(pca_testy,model_nb.predict(pca_testX))\n",
    "print model_nb.score(pca_testX, pca_testy)\n",
    "\n",
    "print cross_val_score(model_nb, trainX, trainy, cv=10).mean()\n",
    "\n",
    "model_nb.fit(trainX, trainy)\n",
    "print classification_report(testy,model_nb.predict(testX))\n",
    "print model_nb.score(testX, testy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also surprising, Naive Bayes doesn't do very well here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.514084714009\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.55      0.02      0.04       282\n",
      "          1       0.44      0.98      0.60       219\n",
      "\n",
      "avg / total       0.50      0.44      0.29       501\n",
      "\n",
      "0.439121756487\n",
      "0.537070078142\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.59      0.09      0.16       282\n",
      "          1       0.44      0.92      0.59       219\n",
      "\n",
      "avg / total       0.52      0.45      0.35       501\n",
      "\n",
      "0.453093812375\n"
     ]
    }
   ],
   "source": [
    "model_dt = DecisionTreeClassifier(max_depth=4, random_state=1)\n",
    "print cross_val_score(model_dt, pca_trainX, pca_trainy, cv=10).mean()\n",
    "\n",
    "model_dt.fit(pca_trainX, pca_trainy)\n",
    "print classification_report(pca_testy,model_dt.predict(pca_testX))\n",
    "print model_dt.score(pca_testX, pca_testy)\n",
    "\n",
    "print cross_val_score(model_dt, trainX, trainy, cv=10).mean()\n",
    "\n",
    "model_dt.fit(trainX, trainy)\n",
    "print classification_report(testy,model_dt.predict(testX))\n",
    "print model_dt.score(testX, testy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Decision Tree does pretty well compared to the others, but still a relatively low score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.562585756708\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.55      0.12      0.20       282\n",
      "          1       0.44      0.87      0.58       219\n",
      "\n",
      "avg / total       0.50      0.45      0.37       501\n",
      "\n",
      "0.449101796407\n",
      "0.552717557328\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.56      0.13      0.21       282\n",
      "          1       0.44      0.87      0.58       219\n",
      "\n",
      "avg / total       0.51      0.45      0.37       501\n",
      "\n",
      "0.453093812375\n"
     ]
    }
   ],
   "source": [
    "model_rf = RandomForestClassifier(max_depth=4, n_estimators=100)\n",
    "print cross_val_score(model_rf, pca_trainX, pca_trainy, cv=10).mean()\n",
    "\n",
    "model_rf.fit(pca_trainX, pca_trainy)\n",
    "print classification_report(pca_testy,model_rf.predict(pca_testX))\n",
    "print model_rf.score(pca_testX, pca_testy)\n",
    "\n",
    "print cross_val_score(model_rf, trainX, trainy, cv=10).mean()\n",
    "\n",
    "model_rf.fit(trainX, trainy)\n",
    "print classification_report(testy,model_rf.predict(testX))\n",
    "print model_rf.score(testX, testy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.549389261567\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.24      0.32       282\n",
      "          1       0.42      0.70      0.52       219\n",
      "\n",
      "avg / total       0.47      0.44      0.41       501\n",
      "\n",
      "0.439121756487\n"
     ]
    }
   ],
   "source": [
    "model_svc = SVC(kernel=\"rbf\",C=5)\n",
    "print cross_val_score(model_svc, pca_trainX, pca_trainy, cv=10).mean()\n",
    "\n",
    "model_svc.fit(pca_trainX, pca_trainy)\n",
    "print classification_report(pca_testy,model_svc.predict(pca_testX))\n",
    "print model_svc.score(pca_testX, pca_testy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So Decision Trees and Support Vector Machines aren't much better either.  \n",
    "Ok, so maybe it doesn't make sense to predict if a novel wins just based on it's synopses or excerpt.  Don't judge a book by it's cover I guess.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
